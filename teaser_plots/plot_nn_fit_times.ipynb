{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nervous-graphic",
   "metadata": {},
   "source": [
    "# Per-sample fit times on binary MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-winter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dotenv\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.subplots\n",
    "import plotly.io as pio\n",
    "\n",
    "import typing\n",
    "import os\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT = True\n",
    "SHOW_TITLES = not EXPORT\n",
    "EXPERIMENT_NAME = 'neural_networks_teaser_plot_fit_times'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-router",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Enable loading of the project module\n",
    "MODULE_DIR = os.path.join(os.path.abspath(os.path.join(os.path.curdir, os.path.pardir, os.pardir)), 'src')\n",
    "sys.path.append(MODULE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import interpolation_robustness as ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT:\n",
    "    EXPORT_DIR = os.path.join(ir.util.REPO_ROOT_DIR, 'logs', f'export_{EXPERIMENT_NAME}')\n",
    "    print('Using export directory', EXPORT_DIR)\n",
    "    if os.path.exists(EXPORT_DIR):\n",
    "        shutil.rmtree(EXPORT_DIR)\n",
    "    os.makedirs(EXPORT_DIR)\n",
    "\n",
    "def export_fig(fig: go.Figure, filename: str):\n",
    "    # If export is disabled then do nothing\n",
    "    if EXPORT:\n",
    "        export_path = os.path.join(EXPORT_DIR, filename)\n",
    "        fig.write_image(export_path)\n",
    "        print('Exported figure at', export_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "ir.plots.setup_plotly_template()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-storm",
   "metadata": {},
   "source": [
    "## Load experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-jungle",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "runs = mlflow.search_runs(\n",
    "    experiment.experiment_id\n",
    ")\n",
    "\n",
    "runs = runs.set_index('run_id', drop=False)  # set index, but keep column to not break stuff depending on it\n",
    "\n",
    "# Convert number of MLP units to integer since they are stored as \"[NUM_UNITS]\" and soprt by them\n",
    "runs['params.mlp_units'] = runs['params.mlp_units'].str.strip('[] \\t').astype(int)\n",
    "runs = runs.sort_values(['params.mlp_units'])\n",
    "print('Loaded', len(runs), 'runs')\n",
    "assert runs['status'].eq('FINISHED').all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-sustainability",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(ir.util.REPO_ROOT_DIR, 'logs', EXPERIMENT_NAME)\n",
    "NUM_SAMPLES = 12873\n",
    "fit_times = np.zeros((len(runs), NUM_SAMPLES))\n",
    "mlp_units = np.zeros((len(runs),), dtype=np.int)\n",
    "for idx, run_id in enumerate(runs.index):\n",
    "    mlp_units[idx] = runs.loc[run_id]['params.mlp_units']\n",
    "    current_fit_times = np.load(os.path.join(LOG_DIR, f'fit_times_{run_id}.npy'))\n",
    "    fit_times[idx] = current_fit_times\n",
    "print('Loaded all fit times')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-ethiopia",
   "metadata": {},
   "source": [
    "## Fit times for different widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-weekend",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(\n",
    "    data=go.Heatmap(\n",
    "        z=fit_times,\n",
    "        x=np.arange(NUM_SAMPLES),\n",
    "        y=mlp_units\n",
    "    )\n",
    ")\n",
    "fig.update_layout(\n",
    "    title='Epoch at which training samples were fit',\n",
    "    xaxis_title='Training sample',\n",
    "    yaxis_title='Number of hidden units',\n",
    "    yaxis_type='category'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the behavior seems to differ for very small and very large models, just take the max epoch per sample for p=10, p=200 and p=10k\n",
    "max_fit_time = np.max(fit_times[[0, -2, -1], :], axis=0)\n",
    "sorted_max_fit_time_indices = np.flip(np.argsort(max_fit_time))\n",
    "sorted_max_fit_time = max_fit_time[sorted_max_fit_time_indices]\n",
    "\n",
    "# Learning rate decay happens at epoch 300, hence throw away all samples which take longer to fit\n",
    "THRESHOLD = 100\n",
    "num_discard = np.argmin(sorted_max_fit_time > THRESHOLD)\n",
    "print('Discarding', num_discard, 'training samples')\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=go.Scatter(\n",
    "        x=np.arange(NUM_SAMPLES),\n",
    "        y=sorted_max_fit_time,\n",
    "        name='Last epoch the sample was fit'\n",
    "    )\n",
    ")\n",
    "fig.add_vline(num_discard - 0.5, line_width=1.0, line_dash='dash', line_color='red')\n",
    "fig.update_layout(\n",
    "    title='Max fit times over p=10 and p=10k',\n",
    "    xaxis_title='Training sample',\n",
    "    yaxis_title='Last epoch the sample was fit'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-habitat",
   "metadata": {},
   "outputs": [],
   "source": [
    "discard_indices = sorted_max_fit_time_indices[:num_discard]\n",
    "print('Training sample indices to discard:')\n",
    "print(np.sort(discard_indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-techno",
   "metadata": {},
   "source": [
    "## Plot the samples that will be discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_xs, train_ys), _, _ = ir.data.make_image_dataset(\n",
    "    dataset=ir.data.Dataset.MNIST,\n",
    "    data_split=ir.data.DataSplit.NoSplit,\n",
    "    binarized_classes=(1, 3),\n",
    "    seed=1\n",
    ")\n",
    "assert train_xs.shape[0] == NUM_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = 10\n",
    "num_rows = int(np.ceil(num_discard / num_cols))\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols)\n",
    "fig.set_size_inches((2 * num_cols, 2 * num_rows))\n",
    "\n",
    "for row_idx in range(num_rows):\n",
    "    for col_idx in range(num_cols):\n",
    "        axes[row_idx, col_idx].xaxis.set_visible(False)\n",
    "        axes[row_idx, col_idx].yaxis.set_visible(False)\n",
    "\n",
    "for idx, sample_idx in enumerate(discard_indices):\n",
    "    row_idx = idx // num_cols\n",
    "    col_idx = idx % num_cols\n",
    "\n",
    "    actual_label = {0: 1, 1: 3}[train_ys[sample_idx]]\n",
    "    axes[row_idx, col_idx].set_title(f'y={actual_label}, idx={sample_idx}')\n",
    "    axes[row_idx, col_idx].imshow(train_xs[sample_idx], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}